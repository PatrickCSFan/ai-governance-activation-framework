# 📊 AI Governance vs Alignment vs Safety vs Responsibility

These terms are often used together—but they mean different things. Here’s a side-by-side comparison to help clarify.

---

## 🧠 Quick Comparison Table

| Term              | What It Focuses On                                  | Key Question                                     |
|-------------------|------------------------------------------------------|--------------------------------------------------|
| **Responsible AI**| Ethics, fairness, transparency, user impact         | Are we building this in a fair and ethical way? |
| **AI Governance** | Oversight, roles, documentation, accountability      | Who is responsible for this system—and how?     |
| **AI Alignment**  | AI behavior vs human intent                         | Is the model doing what we want it to do?       |
| **AI Safety**     | Avoiding unintended harm or dangerous outputs       | Can the system behave in unsafe ways?           |

---

## 🎯 Analogy: Building a Robot

Imagine you're building a robot to help in a hospital.

- **Responsible AI** → Are we considering patient dignity, bias, and ethics?
- **AI Governance** → Who approves the design and monitors its performance?
- **AI Alignment** → Does the robot actually help—not harm—patients based on instructions?
- **AI Safety** → Could it roll over someone's foot or leak private data?

---

## 🔁 How They Work Together

| Concept         | Without It...                                 |
|-----------------|-----------------------------------------------|
| Responsible AI  | We may build useful but unethical systems     |
| AI Governance   | No one is accountable if things go wrong      |
| AI Alignment    | The AI might follow the wrong goals           |
| AI Safety       | The system could cause unintended harm        |

Think of these as **layers of responsible innovation**.  
Strong projects include **all four**, even if done simply.

---

## 📎 Related Glossary

See also: [Glossary of Common Terms](./glossary.md)
