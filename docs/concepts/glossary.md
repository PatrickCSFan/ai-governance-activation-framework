# ðŸ“˜ Glossary of Common AI Governance Terms

This glossary defines key terms in simple, beginner-friendly languageâ€”especially those relevant to teams working with LLMs (Large Language Models).

---

### ðŸ¤– AI / Artificial Intelligence  
Software that can perform tasks that normally require human intelligence, like understanding language, recognizing patterns, or making decisions.

---

### ðŸ¤– LLM / Large Language Model  
A type of AI trained on large text datasets to generate or understand human language (e.g. GPT-4, Claude, Gemini).

---

### ðŸ¤ Responsible AI  
An approach to building and using AI that emphasizes ethics, fairness, transparency, and safety.

---

### ðŸ›ï¸ AI Governance  
The structures, policies, and responsibilities that ensure AI is used safely and appropriately in an organization.

---

### ðŸŽ¯ AI Alignment  
The practice of making sure an AI system behaves in ways that match human values, goals, and intentions.

---

### ðŸ›¡ï¸ AI Safety  
Ensuring AI systems do not cause harmâ€”either through error, misuse, or unintended consequences.

---

### ðŸ” Hallucination  
When an AI generates a confident answer that is completely false or misleading.

---

### ðŸ—‚ï¸ Prompt  
The input or instruction given to an LLM. How you write a prompt can affect the output significantly.

---

### âš–ï¸ Bias (in AI)  
When an AI system produces unfair or discriminatory results, often due to biased training data or design.

---

### ðŸ§ª Red Teaming  
A technique where teams test an AI system to find weaknesses, failures, or safety risks.

---

### ðŸ“‰ Risk Evaluation  
A structured approach to identifying what could go wrong in an AI systemâ€”and how to prevent or reduce it.

---

### ðŸ“ Checklist  
A practical tool to help teams apply governance, alignment, or safety principles step by step.

---

> Want deeper reading? Check out [Stanford HAI](https://hai.stanford.edu), [OpenAI](https://openai.com/research), and [Anthropic](https://www.anthropic.com/).
