# 📘 Glossary of Common AI Governance Terms

This glossary defines key terms in simple, beginner-friendly language—especially those relevant to teams working with LLMs (Large Language Models).

---

### 🤖 AI / Artificial Intelligence  
Software that can perform tasks that normally require human intelligence, like understanding language, recognizing patterns, or making decisions.

---

### 🤖 LLM / Large Language Model  
A type of AI trained on large text datasets to generate or understand human language (e.g. GPT-4, Claude, Gemini).

---

### 🤝 Responsible AI  
An approach to building and using AI that emphasizes ethics, fairness, transparency, and safety.

---

### 🏛️ AI Governance  
The structures, policies, and responsibilities that ensure AI is used safely and appropriately in an organization.

---

### 🎯 AI Alignment  
The practice of making sure an AI system behaves in ways that match human values, goals, and intentions.

---

### 🛡️ AI Safety  
Ensuring AI systems do not cause harm—either through error, misuse, or unintended consequences.

---

### 🔍 Hallucination  
When an AI generates a confident answer that is completely false or misleading.

---

### 🗂️ Prompt  
The input or instruction given to an LLM. How you write a prompt can affect the output significantly.

---

### ⚖️ Bias (in AI)  
When an AI system produces unfair or discriminatory results, often due to biased training data or design.

---

### 🧪 Red Teaming  
A technique where teams test an AI system to find weaknesses, failures, or safety risks.

---

### 📉 Risk Evaluation  
A structured approach to identifying what could go wrong in an AI system—and how to prevent or reduce it.

---

### 📝 Checklist  
A practical tool to help teams apply governance, alignment, or safety principles step by step.

---

> Want deeper reading? Check out [Stanford HAI](https://hai.stanford.edu), [OpenAI](https://openai.com/research), and [Anthropic](https://www.anthropic.com/).
